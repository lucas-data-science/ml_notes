{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deae1221",
   "metadata": {},
   "source": [
    "# Introdução \n",
    "\n",
    "Segue tabela com siglas usadas e seus significados.\n",
    "\n",
    "| Sigla | Significado                             |\n",
    "|-------|------------------------------------------|\n",
    "| AE    | Autoencoder                              |\n",
    "| BPTT  | Backpropagation through time             |\n",
    "| DL    | Deep learning                            |\n",
    "| DNN   | Deep neural network                      |\n",
    "| DRL   | Direct reinforcement learning            |\n",
    "| DDR   | Deep direct reinforcement                |\n",
    "| FDDR  | Fuzzy deep direct reinforcement          |\n",
    "| RDNN  | Recurrent DNN                            |\n",
    "| RL    | Reinforcement learning                   |\n",
    "| NN    | Neural network                           |\n",
    "| SR    | Sharpe ratio                             |\n",
    "| TP    | Total profits                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac7714",
   "metadata": {},
   "source": [
    "Treinar agentes inteligentes para operar automaticamente no mercado financeiro é um tema antigo e amplamente debatido dentro da inteligência artificial moderna. Em essência, o processo de negociação pode ser descrito como um problema de tomada de decisão em tempo real que envolve dois passos fundamentais: compreender o estado atual do mercado e executar a melhor ação possível com base nessa leitura.\n",
    "\n",
    "Diferentemente de tarefas clássicas de aprendizado supervisionado — que contam com dados rotulados por especialistas —, a tomada de decisão dinâmica é mais desafiadora porque exige que o agente explore um ambiente desconhecido sem orientação direta, enquanto precisa agir corretamente em tempo real. Essa capacidade de aprender por conta própria é justamente o foco do aprendizado por reforço (RL), uma abordagem inspirada na forma como seres vivos aprendem a se comportar, com raízes teóricas na neurociência e no controle de comportamento.\n",
    "\n",
    "Do ponto de vista teórico, o RL já foi bem formalizado como um problema de controle ótimo estocástico. Na prática, seus sucessos são comprovados em várias áreas, como navegação de robôs, jogos Atari, e controle de helicópteros. Em alguns casos, os algoritmos de RL chegaram até a superar especialistas humanos em determinadas tarefas. Isso nos leva a uma pergunta importante: será que também é possível treinar um modelo de RL capaz de vencer traders experientes nos mercados financeiros?\n",
    "\n",
    "A resposta a essa pergunta é difícil e envolve dois grandes desafios:\n",
    "\n",
    "1. Como representar e resumir o ambiente financeiro?\n",
    "O mercado financeiro é um ambiente altamente volátil, com dados ruidosos, instáveis e imprevisíveis. Para tentar lidar com isso, analistas costumam usar indicadores técnicos como médias móveis ou estocásticos, com o objetivo de extrair padrões úteis. No entanto, esses indicadores têm limitações — por exemplo, a média móvel pode funcionar bem em tendências claras, mas fracassar em cenários de reversão de tendência.\n",
    "\n",
    "Isso levanta uma nova questão: em vez de depender de indicadores manuais, seria possível extrair automaticamente representações mais robustas diretamente dos dados?\n",
    "\n",
    "2. Como lidar com a execução dinâmica das ordens de compra e venda?\n",
    "Negociar não é apenas tomar decisões a cada instante — é preciso considerar fatores práticos, como custos de transação e “slippage” (desvios entre o preço esperado e o preço real de execução). Se o sistema ficar trocando de posição (entre compra e venda) com muita frequência, isso pode gerar prejuízos mesmo que as decisões estejam corretas em teoria.\n",
    "\n",
    "Além disso, o sistema precisa “lembrar” do que fez no passado: decisões anteriores e posições mantidas influenciam o que deve ser feito agora. Como incluir essa memória no modelo, sem complicar demais a arquitetura?\n",
    "\n",
    "Para enfrentar essas duas questões, os autores propõem uma arquitetura baseada em Redes Neurais Profundas Recorrentes (RDNN). Esse modelo é dividido em duas partes principais:\n",
    "\n",
    "Uma rede profunda (DNN), que aprende automaticamente a extrair características relevantes do mercado;\n",
    "\n",
    "Uma rede recorrente (RNN), que lida com a tomada de decisões no tempo, mantendo memória das ações passadas.\n",
    "\n",
    "Para melhorar ainda mais a robustez frente à incerteza do mercado, os autores incorporam conceitos de aprendizado fuzzy (fuzzy learning), que ajudam a lidar com imprecisões nos dados de entrada.\n",
    "\n",
    "Embora o aprendizado profundo (DL) já tenha se mostrado promissor em áreas como reconhecimento de imagem e fala, esta é a primeira vez, segundo os autores, que ele é implementado para desenvolver um sistema real de negociação financeira com aprendizado por reforço totalmente automatizado.\n",
    "\n",
    "O modelo completo resulta em uma rede neural bastante complexa, combinando profundidade e recorrência. Para treinar esse tipo de rede, é necessário “desenrolar” a parte recorrente no tempo, usando o método conhecido como Backpropagation Through Time (BPTT). No entanto, isso traz um problema: o desaparecimento do gradiente, que dificulta o aprendizado em redes muito profundas.\n",
    "\n",
    "Para contornar isso, os autores propõem um novo método de treinamento chamado BPTT consciente da tarefa (task-aware BPTT). Ele consiste em criar conexões virtuais entre a função objetivo final e camadas profundas da rede durante o treinamento, permitindo que essas camadas “enxerguem” diretamente o impacto de seus ajustes no resultado final — o que melhora a eficiência do aprendizado.\n",
    "\n",
    "O sistema proposto, chamado DDR (Deep Direct Reinforcement), é testado em mercados financeiros reais, usando contratos futuros de ações e de commodities. Os dados históricos desses ativos são utilizados para verificar a performance do modelo.\n",
    "\n",
    "Nas comparações realizadas, os autores mostram que o DDR (e sua versão fuzzy) é mais robusto que outros sistemas de negociação, sendo capaz de gerar lucros consistentes em diferentes condições de mercado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}